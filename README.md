# Data Project Default Kit

The main goal of this project is to provide a standardized foundation and framework for developing data projects. The primary focus is on best practices, automation, testing, and documentation.

## Objectives

- Understand the default project structure: This includes the organization of directories, such as source code, tests, documentation, among others.
- Standard structures in data projects: Practice creating functions and modules to be used and reused in the code.
- Become familiar with development tools: Use of virtual environments (```pyenv```and ```poetry```) to ensure the integrity of the code.
- Versioning with ```git```: Learning how to version your project and use GitHub for collaboration and publishing.
- Testing with ```pytest```: Ensure your code works as expected by creating unit and integration tests.
- Creating tasks with ```taskipy```: creating command shortcuts so you don't have to run one command at a time.
- Project documentation with ```mkdocs```: Learning how to document the project with MKDocs and publish the documentation on GitHub Pages.
    > The ```mkdocs``` documentation for this basic ETL project can be found [here](https://doegemon.github.io/data_project_standard_kit/).
- Automation and CI/CD: Set up continuous integration via GitHub Workflows to maintain project quality.

## References
The initial idea of this project is part of the "How to Structure your Data Project from Scratch" from [Jornada de Dados](https://suajornadadedados.com.br/).

The repository used as reference for this project can be found [here](https://github.com/lvgalvao/DataProjectStarterKit/tree/main).
