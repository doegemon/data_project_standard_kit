{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"ETL Pipeline - Documentation","text":"<p>This is a very simple ETL project focused on using some tools that can (and should) be used in any engineering and data analysis project.</p> <p>This documentation serves to show what was developed in this project.</p>"},{"location":"#overview","title":"Overview","text":"<p>This project involves creating fictitious data on employee absenteeism for a company that does not exist, with this data spread across several Excel files.</p> <p>The pipeline combines all of these files into a single file, with the aim of creating a single source of data. </p>"},{"location":"#details","title":"Details","text":"<p>This is what happens when the pipeline is executed:</p> <pre><code>flowchart LR\n    subgraph ETL[Pipeline]\n    A(Multiple Excel Files) --&gt; B[Extract: extract_from_excel]\n    B[Extract: extract_from_excel] --&gt; |Creates a Dataframe list| C[Transform: concat_dataframes]\n    C[Transform: concat_dataframes] --&gt; |Creates a single Dataframe| D[Load: load_excel]\n    D[Load: load_excel] --&gt; |Dataframe is converted to Excel format| E(Output: single Excel file)\n\n    end</code></pre>"},{"location":"#additional-information","title":"Additional Information","text":"<p>If you want to know more details about the project, you can access its repository.</p>"},{"location":"details/","title":"Detailed Pipeline Documentation","text":"<p>Here are the details of the functions created and used in this pipeline:</p>"},{"location":"details/#extract","title":"<code>extract</code>","text":"<p>Function to read Excel files from a specific folder, convert them to pandas Dataframes, and append these dataframes into a list.</p> <p>args: input_path (str): file path with the Excel files</p> <p>return: list with multiple pandas Dataframes</p> Source code in <code>app/pipeline/extract.py</code> <pre><code>def extract_from_excel(input_path: str) -&gt; List[pd.DataFrame]:\n    \"\"\"\n    Function to read Excel files from a specific folder, convert them to pandas Dataframes, and append these dataframes into a list.\n\n    args:\n    input_path (str): file path with the Excel files\n\n    return:\n    list with multiple pandas Dataframes\n    \"\"\"\n    files = glob.glob(os.path.join(input_path, \"*.xlsx\"))\n\n    if not files:\n        raise ValueError(\"No Excel files found in the specified file path.\")\n    df_list = [pd.read_excel(file) for file in files]\n\n    return df_list\n</code></pre>"},{"location":"details/#transform","title":"<code>transform</code>","text":"<p>Function to concat all dataframes from a list into a single dataframe.</p> <p>args: df_list (List[pd.DataFrame]): a list containing multiple pandas Dataframes</p> <p>return: a single dataframe</p> Source code in <code>app/pipeline/transform.py</code> <pre><code>def concat_dataframes(df_list: List[pd.DataFrame]) -&gt; pd.DataFrame:\n    \"\"\"\n    Function to concat all dataframes from a list into a single dataframe.\n\n    args:\n    df_list (List[pd.DataFrame]): a list containing multiple pandas Dataframes\n\n    return:\n    a single dataframe\n    \"\"\"\n    if not df_list:\n        raise ValueError(\"There are no dataframes to concat.\")\n\n    return pd.concat(df_list, axis=0, ignore_index=True)\n</code></pre>"},{"location":"details/#load","title":"<code>load</code>","text":"<p>Function to convert a single dataframe to an excel file.</p> <p>args: df (pd.DataFrame): pandas dataframe to be converted to excel output_path (str): the path where the excel file will be saved output_file_name (str): the name of the excel file</p> <p>return: \"File saved successfully\"</p> Source code in <code>app/pipeline/load.py</code> <pre><code>def load_excel(df: pd.DataFrame, output_path: str, output_file_name: str) -&gt; str:\n    \"\"\"\n    Function to convert a single dataframe to an excel file.\n\n    args:\n    df (pd.DataFrame): pandas dataframe to be converted to excel\n    output_path (str): the path where the excel file will be saved\n    output_file_name (str): the name of the excel file\n\n    return:\n    \"File saved successfully\"\n    \"\"\"\n    if not os.path.exists(output_path):\n        os.makedirs(output_path)\n\n    df.to_excel(f\"{output_path}/{output_file_name}.xlsx\", index=False)\n\n    return \"File saved successfully\"\n</code></pre>"},{"location":"details/#etl","title":"<code>etl</code>","text":"<p>Function to execute all the steps of the ETL pipeline.</p> <p>args: input_path (str): file path with the excel files output_path (str): the path where the consolidated excel file will be saved output_file_name (str): the name of the consolidated excel file</p> <p>return: \"Pipeline executed successfully\"</p> Source code in <code>app/pipeline/etl.py</code> <pre><code>def etl_pipeline(input_path: str, output_path: str, output_file_name: str) -&gt; str:\n    \"\"\"\n    Function to execute all the steps of the ETL pipeline.\n\n    args:\n    input_path (str): file path with the excel files\n    output_path (str): the path where the consolidated excel file will be saved\n    output_file_name (str): the name of the consolidated excel file\n\n    return:\n    \"Pipeline executed successfully\"\n    \"\"\"\n    df_list = extract_from_excel(input_path)\n    consolidated_df = concat_dataframes(df_list)\n    load_excel(consolidated_df, output_path, output_file_name)\n\n    return print(\"Pipeline executed successfully.\")\n</code></pre>"}]}